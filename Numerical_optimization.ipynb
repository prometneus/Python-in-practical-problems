{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Numerical optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDC-sDiHRQ-l"
      },
      "source": [
        "import numpy as np\n",
        "from sympy import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz4-M6IWcWNh"
      },
      "source": [
        "### Method of the steepest descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNO8A9rCRafH"
      },
      "source": [
        "### Denote variables and function, set constants and first point\n",
        "x,y,h = symbols('x y h', real=True)\n",
        "epsilon = 0.01\n",
        "target_function = 5*x**2 + 4*y**2 + 3*x - 4*y + 2\n",
        "point = (-0.2, 0.4)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "id": "Rhn-CjBMXWBO",
        "outputId": "984962cf-b820-4b44-cc97-c6a4bdadc2f9"
      },
      "source": [
        "### Calculate the gradient of the function\n",
        "gradient = Matrix([[diff(target_function, x)], [diff(target_function, y)]])\n",
        "gradient"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}10 x + 3\\\\8 y - 4\\end{matrix}\\right]$",
            "text/plain": [
              "Matrix([\n",
              "[10*x + 3],\n",
              "[ 8*y - 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze91LsZ0YRP7",
        "outputId": "80064624-370d-419c-c695-79008cfbb35e"
      },
      "source": [
        "subbed = gradient.subs({x:point[0], y:point[1]}) # Substitute the first point in the gradient, set the stop condition\n",
        "i = 1 # Just an iteration counter\n",
        "while abs(max(subbed)) > epsilon: # While stop condition is not satisfied, continue\n",
        "  print(f'Iteration {i} begun')\n",
        "  ### STEP 1 ###\n",
        "  Phi_function = target_function.replace(x, (point[0] - subbed[0]*h)) # A function to find alpha multiplier\n",
        "  Phi_function = expand(Phi_function.replace(y, (point[1] - subbed[1]*h)))\n",
        "  print(Phi_function)\n",
        "  ### STEP 2 ### \n",
        "  alpha = solve(Eq(Phi_function, minimum(Phi_function, h)), h)[1] # By finding min find alpha multiplier\n",
        "  print(f'Minumum of this function is {alpha}')\n",
        "  ### STEP 3 ###\n",
        "  point = (point[0] - alpha*subbed[0], point[1] - alpha*subbed[1]) # Make a step and find a new point\n",
        "  print(f'Newly estimated point {point}\\n')\n",
        "  subbed = gradient.subs({x:point[0], y:point[1]}) # Substitute new point to check condition\n",
        "  i+=1\n",
        "true_answer = (-0.3, 0.5)\n",
        "print(f'The error with the real answer was {tuple(x-y for x, y in zip(true_answer, point))}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 begun\n",
            "7.56*h**2 - 1.64*h + 0.64\n",
            "Minumum of this function is 0.108465611173925\n",
            "Newly estimated point (-0.308465611173925, 0.486772488939140)\n",
            "\n",
            "Iteration 2 begun\n",
            "0.0806248507835254*h**2 - 0.0183645483821793*h + 0.551058201058201\n",
            "Minumum of this function is 0.113888940828598\n",
            "Newly estimated point (-0.298824216273274, 0.498824226735299)\n",
            "\n",
            "Iteration 3 begun\n",
            "0.00104513903513254*h**2 - 0.000226723074482314*h + 0.55001244210794\n",
            "Minumum of this function is 0.108466072653813\n",
            "Newly estimated point (-0.300099542704556, 0.499844478802127)\n",
            "\n",
            "The error with the real answer was (9.95427045563102e-5, 0.000155521197873210)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLrKoYZ6rnAe"
      },
      "source": [
        "### Conjugate gradient method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpR3NAZuQhL"
      },
      "source": [
        "### Denote variables and function, set constants and first point\n",
        "x,y,h = symbols('x y h', real=True)\n",
        "epsilon = 0.01\n",
        "target_function = 5*x**2 + 4*y**2 + 3*x - 4*y + 2\n",
        "point = (-0.2, 0.4)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "id": "85qIREnsuSGl",
        "outputId": "f3cb4196-0674-4fdc-9a3a-3f66adc1f429"
      },
      "source": [
        "### Calculate the gradient of the function\n",
        "gradient = Matrix([[diff(target_function, x)], [diff(target_function, y)]])\n",
        "gradient"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}10 x + 3\\\\8 y - 4\\end{matrix}\\right]$",
            "text/plain": [
              "Matrix([\n",
              "[10*x + 3],\n",
              "[ 8*y - 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6-om4OzAsEO",
        "outputId": "dd464b2a-ab10-46d2-c1ff-9a270b377f07"
      },
      "source": [
        "for i in range(2):\n",
        "  ### STEP 0 ### \n",
        "  if i == 0:\n",
        "    H = -gradient.subs({x:point[0], y:point[1]})\n",
        "  else:\n",
        "    H = -gradient.subs({x:point[0], y:point[1]}) + beta*H\n",
        "  ### STEP 1 ###\n",
        "  Phi_function = target_function.replace(x, (point[0] + H[0]*h)) # A function to find alpha multiplier\n",
        "  Phi_function = expand(Phi_function.replace(y, (point[1] + H[1]*h)))\n",
        "  print(Phi_function)\n",
        "  ### STEP 2 ###\n",
        "  alpha = solve(Eq(Phi_function, minimum(Phi_function, h)), h)[1] # By finding min find alpha multiplier\n",
        "  print(f'Minumum of this function is {alpha}')\n",
        "  ### STEP 3 ###\n",
        "  previous_point = point\n",
        "  point = (point[0] + alpha*H[0], point[1] + alpha*H[1]) # Make a step and find a new point\n",
        "  print(f'Newly estimated point {point}\\n')\n",
        "  if i == 1:\n",
        "    true_answer = (-0.3, 0.5)\n",
        "    print(f'The error with the real answer was {tuple(x-y for x, y in zip(true_answer, point))}')\n",
        "    break\n",
        "  ### STEP 4 ###\n",
        "  numerator = gradient.subs({x:point[0], y:point[1]}).dot(gradient.subs({x:point[0], y:point[1]})) # Beta coefficient estimation\n",
        "  denominator = gradient.subs({x:previous_point[0], y:previous_point[1]}).dot(gradient.subs({x:previous_point[0], y:previous_point[1]}))\n",
        "  beta = numerator/denominator\n",
        "  print(f'beta is {round(beta, 6)}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.56*h**2 - 1.64*h + 0.64\n",
            "Minumum of this function is 0.108465611173925\n",
            "Newly estimated point (-0.308465611173925, 0.486772488939140)\n",
            "\n",
            "beta is 0.011198\n",
            "0.0796768765787679*h**2 - 0.0183645479236285*h + 0.551058201058201\n",
            "Minumum of this function is 0.115243937832549\n",
            "Newly estimated point (-0.299999997051647, 0.500000004283073)\n",
            "\n",
            "The error with the real answer was (-2.94835283964900e-9, -4.28307322941635e-9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV8I3vJPGiqm"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}